{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import codecs\n",
    "\n",
    "import sys\n",
    "stdout = sys.stdout\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')\n",
    "sys.stdout = stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import multiprocessing\n",
    "from konlpy.tag import Mecab\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = []\n",
    "mecab = Mecab()\n",
    "\n",
    "for news_name in ['chosun_full', 'donga_full', 'hani_full', 'joongang_full', 'kh_full'] :\n",
    "    with open('./Data/news/'+ news_name + '.txt', 'r') as f:\n",
    "        lines = f.read()\n",
    "        sentences = lines.split('.')\n",
    "        \n",
    "        for i in range(len(sentences)):\n",
    "            dic = mecab.morphs(sentences[i])\n",
    "            dicSize = len(dic)\n",
    "                    \n",
    "            for idx in range(dicSize-1):\n",
    "                if(idx==dicSize):\n",
    "                        break\n",
    "                \n",
    "                else:\n",
    "                    if(dic[idx]=='새' and dic[(idx+1)]=='정치') :\n",
    "                        dic.remove('새')\n",
    "                        dic.remove('정치')\n",
    "                        dic.insert(idx,\"새정치\")\n",
    "                        dicSize = dicSize-1\n",
    "            \n",
    "            for word in dic:\n",
    "                text.append(word)\n",
    "    print(news_name + \"finished\")\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2vec success\n",
      "model.wv assign success\n",
      "model saved success\n",
      "Elapsed time: 5484.52880979 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time() \n",
    "\n",
    "\n",
    "modelCbow= Word2Vec(text, min_count=15, size = 300, sg=0, iter= 10) #sg=0 : cbow\n",
    "modelSkip = Word2Vec(text, min_count=15, size = 300, sg=1, iter= 10) #sg=1 : skip gram\n",
    "print(\"word2vec success\")\n",
    "\n",
    "vectorsCbow = modelCbow.wv\n",
    "vectorsSkip = modelSkip.wv\n",
    "print(\"model.wv assign success\")\n",
    "\n",
    "vectorsCbow.save('modelCbow.bin')\n",
    "vectorsSkip.save('modelSkip.bin')\n",
    "print(\"model saved success\")\n",
    "\n",
    "\n",
    "print(\"Elapsed time: %s seconds\" %(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**loading models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vectors = KeyedVectors.load('modelSkip.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**word similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[박근혜]'s most similar: [당선인] 0.737558364868\n",
      "[오바마]'s most similar: [버락] 0.92061662674\n",
      "[김정은]'s most similar: [김정일] 0.658897936344\n",
      "[아베]'s most similar: [신조] 0.891100943089\n",
      "[청와대]'s most similar: [비서관] 0.674301207066\n",
      "[백악관]'s most similar: [좌관] 0.667192935944\n",
      "[새누리당]'s most similar: [새정치민주연합] 0.807204842567\n",
      "[최순실]'s most similar: [강난희] 0.751282215118\n"
     ]
    }
   ],
   "source": [
    "name_list = [\"박근혜\",\"오바마\",\"김정은\",\"아베\",\"청와대\",\"백악관\",\"새누리당\",\"최순실\"]\n",
    "\n",
    "for idx in range(len(name_list)):\n",
    "    name_list[idx] = name_list[idx].encode(\"utf-8\")\n",
    "\n",
    "similarity_list = []\n",
    "for name in name_list:\n",
    "    name = name.encode(\"utf-8\")\n",
    "    w = word_vectors.most_similar(name, topn=1)\n",
    "    w1 = w[0][0]\n",
    "    w2 = w[0][1]\n",
    "    print \"[%s]'s most similar: [%s]\" %(name, w1),\n",
    "    print(w2)\n",
    "    similarity_list.append(\"[%s]'s most similar: [%s]\" % (name, (w)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**word analogy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[서울+북한-한국] corresponds to [평양]\n",
      "[박근혜+북한-한국] corresponds to [당선인]\n",
      "[보수+새정치-새누리당] corresponds to [진보]\n",
      "[민주주의+북한-한국] corresponds to [비핵화]\n",
      "[새누리당+미국-한국] corresponds to [민주당]\n",
      "[박근혜+일본-한국] corresponds to [아베]\n",
      "[박근혜+미국-한국] corresponds to [오바마]\n",
      "[서울+일본-한국] corresponds to [도쿄]\n",
      "[청와대+미국-한국] corresponds to [백악관]\n",
      "[김무성+새정치-새누리당] corresponds to [김한길]\n",
      "[서울+미국-한국] corresponds to [워싱턴]\n"
     ]
    }
   ],
   "source": [
    "def word_analogy(w1, w2, w3):\n",
    "    return word_vectors.most_similar(positive=[w1, w2], negative=[w3], topn=1)\n",
    "\n",
    "words_list = [[\"서울\",\"일본\",\"한국\"],[\"서울\",\"미국\",\"한국\"],[\"서울\",\"북한\",\"한국\"],\n",
    "                [\"박근혜\",\"일본\",\"한국\"],[\"박근혜\",\"미국\",\"한국\"],[\"박근혜\",\"북한\",\"한국\"],\n",
    "                [\"새누리당\",\"미국\",\"한국\"],[\"청와대\",\"미국\",\"한국\"],[\"민주주의\",\"북한\",\"한국\"],\n",
    "                [\"김무성\",\"새정치\",\"새누리당\"],[\"보수\",\"새정치\",\"새누리당\"]]\n",
    "\n",
    "for element in words_list:\n",
    "    for idx in range(len(element)):\n",
    "        element[idx] = element[idx].encode(\"utf-8\")\n",
    "\n",
    "d = {\"%s+%s-%s\"%(words[0],words[1],words[2]):word_analogy(words[0],words[1],words[2])[0][0] for words in words_list}\n",
    "\n",
    "for key in d:\n",
    "    print \"[%s] corresponds to [%s]\" % (key, d[key])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
