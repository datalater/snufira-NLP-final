{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import codecs\n",
    "\n",
    "import sys\n",
    "stdout = sys.stdout\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')\n",
    "sys.stdout = stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import multiprocessing\n",
    "from konlpy.tag import Mecab\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chosun_fullfinished\n",
      "donga_fullfinished\n",
      "hani_fullfinished\n",
      "joongang_fullfinished\n",
      "kh_fullfinished\n"
     ]
    }
   ],
   "source": [
    "text = []\n",
    "mecab = Mecab()\n",
    "\n",
    "for news_name in ['chosun_full', 'donga_full', 'hani_full', 'joongang_full', 'kh_full'] :\n",
    "    with open('./Data/news/'+ news_name + '.txt', 'r') as f:\n",
    "        lines = f.read()\n",
    "        sentences = lines.split('.')\n",
    "        \n",
    "        for i in range(len(sentences)):\n",
    "            dic = mecab.morphs(sentences[i])\n",
    "            dicSize = len(dic)\n",
    "                    \n",
    "            for idx in range(dicSize-1):\n",
    "                if(idx==dicSize):\n",
    "                        break\n",
    "                \n",
    "                else:\n",
    "                    if(dic[idx]=='새' and dic[(idx+1)]=='정치') :\n",
    "                        dic.remove('새')\n",
    "                        dic.remove('정치')\n",
    "                        dic.insert(idx,\"새정치\")\n",
    "                        dicSize = dicSize-1\n",
    "            \n",
    "            text.append(dic)\n",
    "    print(news_name + \"finished\")\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word2Vec**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2vec success\n",
      "model.wv assign success\n",
      "model saved success\n",
      "Elapsed time: 6149.90368104 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time() \n",
    "\n",
    "\n",
    "modelCbow= Word2Vec(text, min_count=15, size = 100, sg=0, iter= 10) #sg=0 : cbow\n",
    "modelSkip = Word2Vec(text, min_count=15, size = 100, sg=1, iter= 10) #sg=1 : skip gram\n",
    "print(\"word2vec success\")\n",
    "\n",
    "vectorsCbow = modelCbow.wv\n",
    "vectorsSkip = modelSkip.wv\n",
    "print(\"model.wv assign success\")\n",
    "\n",
    "vectorsCbow.save('modelCbow_100_10.bin')\n",
    "vectorsSkip.save('modelSkip_100_10.bin')\n",
    "print(\"model saved success\")\n",
    "\n",
    "\n",
    "print(\"Elapsed time: %s seconds\" %(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FastText**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vectors = KeyedVectors.load('./modelCbow_100_10.bin')\n",
    "word_vectors2 = KeyedVectors.load('./modelSkip_100_10.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Model : word_vectors\n",
      "[박근혜]'s most similar: [이명박] 0.799136817455\n",
      "[오바마]'s most similar: [푸틴] 0.764352440834\n",
      "[김정은]'s most similar: [김정일] 0.804682195187\n",
      "[아베]'s most similar: [노다] 0.827440142632\n",
      "[청와대]'s most similar: [인수위] 0.805438101292\n",
      "[백악관]'s most similar: [국무부] 0.711315095425\n",
      "[새누리당]'s most similar: [민주당] 0.942853689194\n",
      "[최순실]'s most similar: [강난희] 0.801293849945\n",
      "\n",
      "Current Model : word_vectors2\n",
      "[박근혜]'s most similar: [당선인] 0.831447839737\n",
      "[오바마]'s most similar: [버락] 0.954790949821\n",
      "[김정은]'s most similar: [장성택] 0.721488296986\n",
      "[아베]'s most similar: [신조] 0.932793855667\n",
      "[청와대]'s most similar: [김기춘] 0.823307573795\n",
      "[백악관]'s most similar: [좌관] 0.811292886734\n",
      "[새누리당]'s most similar: [새정치민주연합] 0.929177343845\n",
      "[최순실]'s most similar: [노재헌] 0.732822179794\n"
     ]
    }
   ],
   "source": [
    "name_list = [\"박근혜\",\"오바마\",\"김정은\",\"아베\",\"청와대\",\"백악관\",\"새누리당\",\"최순실\"]\n",
    "\n",
    "for idx in range(len(name_list)):\n",
    "    name_list[idx] = name_list[idx].encode(\"utf-8\")\n",
    "\n",
    "print(\"Current Model : word_vectors\")\n",
    "    \n",
    "similarity_list = []\n",
    "for name in name_list:\n",
    "    name = name.encode(\"utf-8\")\n",
    "    w = word_vectors.most_similar(unicode(name,\"utf-8\"), topn=1)\n",
    "    w1 = w[0][0]\n",
    "    w2 = w[0][1]\n",
    "    print \"[%s]'s most similar: [%s]\" %(name, w1),\n",
    "    print(w2)\n",
    "    similarity_list.append(\"[%s]'s most similar: [%s]\" % (name, (w)))\n",
    "\n",
    "print(\"\\nCurrent Model : word_vectors2\")\n",
    "    \n",
    "similarity_list = []\n",
    "for name in name_list:\n",
    "    name = name.encode(\"utf-8\")\n",
    "    w = word_vectors2.most_similar(unicode(name,\"utf-8\"), topn=1)\n",
    "    w1 = w[0][0]\n",
    "    w2 = w[0][1]\n",
    "    print \"[%s]'s most similar: [%s]\" %(name, w1),\n",
    "    print(w2)\n",
    "    similarity_list.append(\"[%s]'s most similar: [%s]\" % (name, (w)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word analogy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Model : word_vectors\n",
      "[서울+일본-한국] corresponds to [오사카]\n",
      "[서울+미국-한국] corresponds to [워싱턴]\n",
      "[서울+북한-한국] corresponds to [선릉역]\n",
      "[박근혜+일본-한국] corresponds to [아베]\n",
      "[박근혜+미국-한국] corresponds to [오바마]\n",
      "[박근혜+북한-한국] corresponds to [여당]\n",
      "[새누리당+미국-한국] corresponds to [민주당]\n",
      "[새정치+미국-한국] corresponds to [민주당]\n",
      "[청와대+미국-한국] corresponds to [백악관]\n",
      "[민주주의+북한-한국] corresponds to [자유민주주의]\n",
      "[김무성+새정치-새누리당] corresponds to [김한길]\n",
      "[보수+새정치-새누리당] corresponds to [DJP]\n",
      "\n",
      "Current Model : word_vectors2\n",
      "[서울+일본-한국] corresponds to [종로구]\n",
      "[서울+미국-한국] corresponds to [맨해튼]\n",
      "[서울+북한-한국] corresponds to [선부]\n",
      "[박근혜+일본-한국] corresponds to [대통령]\n",
      "[박근혜+미국-한국] corresponds to [오바마]\n",
      "[박근혜+북한-한국] corresponds to [대통령]\n",
      "[새누리당+미국-한국] corresponds to [공화]\n",
      "[새정치+미국-한국] corresponds to [공화]\n",
      "[청와대+미국-한국] corresponds to [백악관]\n",
      "[민주주의+북한-한국] corresponds to [적화통일]\n",
      "[김무성+새정치-새누리당] corresponds to [김한길]\n",
      "[보수+새정치-새누리당] corresponds to [좌파]\n"
     ]
    }
   ],
   "source": [
    "words_list = [[\"서울\",\"일본\",\"한국\"],[\"서울\",\"미국\",\"한국\"],[\"서울\",\"북한\",\"한국\"],\n",
    "                [\"박근혜\",\"일본\",\"한국\"],[\"박근혜\",\"미국\",\"한국\"],[\"박근혜\",\"북한\",\"한국\"],\n",
    "                [\"새누리당\",\"미국\",\"한국\"],[\"새정치\",\"미국\",\"한국\"],[\"청와대\",\"미국\",\"한국\"],[\"민주주의\",\"북한\",\"한국\"],\n",
    "                [\"김무성\",\"새정치\",\"새누리당\"],[\"보수\",\"새정치\",\"새누리당\"]]\n",
    "\n",
    "print(\"Current Model : word_vectors\")\n",
    "for words in words_list:\n",
    "    a= word_vectors.most_similar(positive=[unicode(words[0],\"utf-8\"),unicode(words[1],\"utf-8\")], negative=[unicode(words[2],\"utf-8\")], topn=1)\n",
    "    print \"[%s+%s-%s] corresponds to [%s]\" % (words[0], words[1], words[2], a[0][0].encode(\"utf-8\"))\n",
    "    \n",
    "print(\"\\nCurrent Model : word_vectors2\")\n",
    "for words in words_list:\n",
    "    a= word_vectors2.most_similar(positive=[unicode(words[0],\"utf-8\"),unicode(words[1],\"utf-8\")], negative=[unicode(words[2],\"utf-8\")], topn=1)\n",
    "    print \"[%s+%s-%s] corresponds to [%s]\" % (words[0], words[1], words[2], a[0][0].encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
